{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "In this file, we will do a classification problem using the dataset CIFAR10, the dataset contains 50K images for the training set from 10 different classes(ie 5K for each class), and 10K for the test set(ie 1K for each class). One image of CIFAR10 is of size 3x32x32. The different classes in CIFAR10 are \n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "The test set contains images. Our model will be a Convolutional Neural Network\n",
    "So these are the next steps for our training:\n",
    "    \n",
    "    1- We do the data preprocessing (loading, normalizing, data augmentation ...)\n",
    "    2- We define our model (Convolutional Neural Network)\n",
    "    3- We define our loss function\n",
    "    4- Train the model on the training data\n",
    "    5- Test the model on the test data\n",
    "    6- Print the accuracy on each class of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "random.seed(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Load and Normalize the data - Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualize some data first in CIFAR10\n",
    "data = CIFAR10('./cifar10', download= False, train= True)\n",
    "\n",
    "#Function for displaying images\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = 20, 40\n",
    "\n",
    "#img = torch.stack( (torch.stack((torch.asarray(dataset[i][0]) for _ in range(n)),dim = 0)\n",
    "#                    for i in range(10)), dim = 1)\n",
    "    \n",
    "def show_dataset(dataset, n = 4):\n",
    "    img = np.vstack((np.hstack((np.asarray(dataset[i][0]) for _ in range(n)))\n",
    "                    for i in range(10)))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "show_dataset(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),    \n",
    "    ])\n",
    "\n",
    "trainset = CIFAR10('./cifar10', download = False, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size= 25, shuffle= True)\n",
    "testset = CIFAR10('./cifar10', download = False, train = False, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size= 25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Training set: \",(trainset))\n",
    "print(\"Test set: \", (testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Define our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=9, kernel_size=5)  # output size after conv = 28, after pool= 14\n",
    "        self.conv2 = nn.Conv2d(in_channels=9, out_channels=18, kernel_size=4) # output size after conv = 10, after pool= 5\n",
    "        self.fc1 = nn.Linear(in_features=18*5*5, out_features=1000)\n",
    "        self.fc2 = nn.Linear(in_features=1000, out_features=500)\n",
    "        self.fc3 = nn.Linear(in_features=500, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(-1, 18*5*5)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "model = MyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Define our Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since we are dealing with a classification problem, we define a cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lossList = []\n",
    "do = nn.Dropout(p = 0.5) #dropout to avoid overfitting\n",
    "\n",
    "for epoch in range(25):\n",
    "    correct = 0\n",
    "    for data in trainloader:\n",
    "        inp, labels = data   #get the inputs of the training set        \n",
    "        \n",
    "        optimizer.zero_grad()   #set the optimizer to zero\n",
    "        \n",
    "        inputs = do(inp)   #apply the dropout\n",
    "        outputs = model(inputs) #forward pass\n",
    "        \n",
    "        loss = criterion(outputs, labels) #compute the loss\n",
    "        loss.backward()      #backward pass\n",
    "        optimizer.step()     #updating parameters\n",
    "        \n",
    "        pred = torch.argmax(outputs, dim= 1)\n",
    "        for j in range(len(inputs)):\n",
    "            if (pred[j]==labels[j]):\n",
    "                correct += 1\n",
    "    print(\"Epoch:\", epoch+1,\" - Loss=\", loss.item(), \"- Training Accuracy=\", 100*correct / len(trainset))\n",
    "    lossList.append(loss.item())\n",
    "        \n",
    "print(\"Finished Training\")\n",
    "\n",
    "#plot the loss function\n",
    "epoch_range = range(0, len(lossList))\n",
    "plt.figure(figsize=[7,5])\n",
    "plt.plot(epoch_range, lossList)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        #get the inputs of the test set\n",
    "        inputs, labels = data\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        pred = torch.argmax(outputs, dim=1) #return the index which is the number of the corresponding class\n",
    "        for i in range (len(pred)):\n",
    "            if (pred[i].item()==labels[i].item()):\n",
    "                correct += 1\n",
    "        total += len(labels)\n",
    "        #print(\"Accuracy =\", correct / total)\n",
    "print(\"Accuracy over 10000 images =\", 100*correct / total,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
